# Before every training check:
# gpu
# session_id = <selected_name>_<model_used>_<number_of_run>, example: us_cnn_1 or us_crnn_1 (us_model_run)
# selected name should report the name of the dataset used so to remember them
# model
# run
# concatenation of data
# data augmentation
# name of files 
# mel bands
fast_run: 0
processing: 'CPU'
gpu: "1"
allow_growth: "True"
base_dir: "/nas/home/fronchini/EUSIPCO/urban-sound-class"
log_dir: "/nas/home/fronchini/EUSIPCO/urban-sound-class/logdir"
session_id: "audiogen3_cnn_1"
run: 1
model: CNN # Cnn for Salamon netwok, CRNN for Cobos network
concat_data: -1 # 0 for only real data or real+aug, 1 for concatentaion of data, -1 for only fake data
n_rep: 3 # number of repetition of the dataset [1, 2, 3, 4]
data_aug: None # T for TimeStretch, P for PitchShift, None if not data augmentation applied, P1_all, P2_all T1_all if I want to ge them all
training:
  batch_size: 128
  batch_size_val: 64
  n_epochs: 100 # max num epochs
  val_thresholds: [0.5] # thresholds used to compute f1 intersection in validation.
testing:
  batch_size: 1
  mode: a # [a or f] for the entire dataset (all clip) and f is for frame by frame at validation and testing time
data: # change with your paths if different.
  # NOTE: if you have data in 44kHz only then synth_folder will be the path where
  # resampled data will be placed.
  metadata_file_real: "/nas/home/fronchini/EUSIPCO/urban-sound-class/UrbanSound8K/metadata/UrbanSound8K.csv"
  metadata_file_fake: "/nas/home/fronchini/EUSIPCO/urban-sound-class/audio_generation/AUDIOGEN_dataset"
  audio_dir_real: "/nas/home/fronchini/EUSIPCO/urban-sound-class/UrbanSound8K/audio"
  audio_dir_fake: "/nas/home/fronchini/EUSIPCO/urban-sound-class/audio_generation/AUDIOGEN_dataset"
  img: "/nas/home/fronchini/EUSIPCO/urban-sound-class/img"
  checkpoint_folder: "./checkpoint"
  audio_max_len: 4
  patch_lenght_s: 3
  normalization: "spec" # [spec or dataset], spec when normalization spec by spec, dataset when normalizing considering the whole dataset
opt:
  lr: 0.001
feats:
  n_mels: 64
  n_filters: 2048
  hop_length: 1024
  n_window: 1024
  sample_rate: 16000
  f_min: 0
  f_max: 8000
net:
  kernel_size: 5
  stride: 1
  padding: 2
  dense_drop: [0.5, 0.5]
  maxp_ks: [4, 2]
  maxp_stride: [4, 2]
  nclass: 10
  in_channel: [1, 24, 48]
  out_channel: [24, 48, 48]
  dense_in: [336, 64]
  dense_out: [64, 10]
  

        